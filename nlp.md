# Awesome Machine Learning Fairness - Natural Language Processing

## Survey

1. [Language (Technology) is Power: A Critical Survey of “Bias” in NLP](https://aclanthology.org/2020.acl-main.485.pdf), ACL'20

## Algorithm

1. [MABEL: Attenuating Gender Bias using Textual Entailment Data](https://aclanthology.org/2022.emnlp-main.657.pdf), EMNLP'22
1. [Features or Spurious Artifacts? Data-centric Baselines for Fair and Robust Hate Speech Detection](https://aclanthology.org/2022.naacl-main.221.pdf), NAACL'22
1. [Towards Understanding and Mitigating Social Biases in Language Models](http://proceedings.mlr.press/v139/liang21a/liang21a.pdf), ICML'21
1. [FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders](https://openreview.net/pdf?id=N6JECD-PI5w), ICLR'21
1. [The Effect of Round-Trip Translation on Fairness in Sentiment Analysis](https://aclanthology.org/2021.emnlp-main.363.pdf), ACL'21
1. [Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation](https://aclanthology.org/2020.acl-main.484.pdf), ACL'20
1. [Towards Debiasing Sentence Representations](https://aclanthology.org/2020.acl-main.488.pdf), ACL'20
1. [Gender Bias in Contextualized Word Embeddings](https://aclanthology.org/N19-1064.pdf), NAACL'19
1. [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://proceedings.neurips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf), NeurIPS'16

## Evaluation

1. [Holistic Evaluation of Language Models](https://arxiv.org/pdf/2211.09110.pdf), arXiv'22
2. [On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations](https://aclanthology.org/2022.acl-short.62.pdf), ACL'22
3. [Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models](https://aclanthology.org/2022.naacl-main.122.pdf), NAACL'22
4. [BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation](https://arxiv.org/pdf/2101.11718.pdf), FAccT'21
5. [Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets](https://aclanthology.org/2021.acl-long.81.pdf), ACL'21
6. [StereoSet: Measuring stereotypical bias in pretrained language models](https://aclanthology.org/2021.acl-long.416.pdf), ACL'21
7. [CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models](https://aclanthology.org/2020.emnlp-main.154.pdf), EMNLP'20
8. [On Measuring Social Biases in Sentence Encoders](https://aclanthology.org/N19-1063.pdf), NAACL'19
9. [Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods](https://aclanthology.org/N18-2003.pdf), NAACL'18
10. [Gender Bias in Coreference Resolution](https://aclanthology.org/N18-2002.pdf), NAACL'18

## Pre-training

1. [Measuring and Reducing Gendered Correlations in Pre-trained Models](https://arxiv.org/pdf/2010.06032.pdf), arXiv'21