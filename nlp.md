# Awesome Machine Learning Fairness - Natural Language Processing

1. [Language (Technology) is Power: A Critical Survey of “Bias” in NLP](https://aclanthology.org/2020.acl-main.485.pdf), ACL'20

1. [Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models](https://aclanthology.org/2022.naacl-main.122.pdf), NAACL'22
1. [Features or Spurious Artifacts? Data-centric Baselines for Fair and Robust Hate Speech Detection](https://aclanthology.org/2022.naacl-main.221.pdf), NAACL'22
1. [Towards Understanding and Mitigating Social Biases in Language Models](http://proceedings.mlr.press/v139/liang21a/liang21a.pdf), ICML'21
1. [FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders](https://openreview.net/pdf?id=N6JECD-PI5w), ICLR'21
1. [The Effect of Round-Trip Translation on Fairness in Sentiment Analysis](https://aclanthology.org/2021.emnlp-main.363.pdf), ACL'21
1. [Measuring and Reducing Gendered Correlations in Pre-trained Models](https://arxiv.org/pdf/2010.06032.pdf), arXiv'21
1. [Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation](https://aclanthology.org/2020.acl-main.484.pdf), ACL'20
1. [Towards Debiasing Sentence Representations](https://aclanthology.org/2020.acl-main.488.pdf), ACL'20
1. [Gender Bias in Contextualized Word Embeddings](https://aclanthology.org/N19-1064.pdf), NAACL'19
1. [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://proceedings.neurips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf), NeurIPS'16